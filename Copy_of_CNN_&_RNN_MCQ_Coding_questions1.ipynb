{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rutujapalatkar27/upgraded-octo-invention/blob/main/Copy_of_CNN_%26_RNN_MCQ_Coding_questions1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zGp9oN3fzz56"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, Dense\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import warnings\n",
        "\n",
        "# Ignore all warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg-h6dNnCBFa"
      },
      "source": [
        "**Question 11**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm9D27zDEFxb",
        "outputId": "ffad0cbb-ee48-49d7-bca0-3982c145fa4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[np.int64(6), np.int64(5)]\n",
            "[np.int64(8), np.int64(9)]\n"
          ]
        }
      ],
      "source": [
        "def max_pooling(matrix, pool_size, stride):\n",
        "    \"\"\"\n",
        "    Perform max pooling on a 2D matrix.\n",
        "\n",
        "    Args:\n",
        "        matrix (list of list of int/float): Input 2D matrix.\n",
        "        pool_size (int): Size of the pooling window (pool_size x pool_size).\n",
        "        stride (int): Stride for moving the pooling window.\n",
        "\n",
        "    Returns:\n",
        "        list of list of float: Resultant matrix after max pooling.\n",
        "    \"\"\"\n",
        "    # Convert the input matrix to a numpy array for easier manipulation\n",
        "    matrix = np.array(matrix)\n",
        "    rows, cols = matrix.shape\n",
        "\n",
        "    # Determine the dimensions of the output matrix\n",
        "    out_rows = matrix.shape[1] // stride\n",
        "    out_cols = matrix.shape[0] // stride\n",
        "\n",
        "    # Initialize the output matrix\n",
        "    pooled_matrix = []\n",
        "\n",
        "    # Perform max pooling\n",
        "    for i in range(0, out_rows * stride, stride):\n",
        "        row = []\n",
        "        for j in range(0, out_cols * stride, stride):\n",
        "            # Extract the current pooling window\n",
        "            pool_window = matrix[i:i+pool_size, j:j+pool_size]\n",
        "            # Append the maximum value in the pooling window\n",
        "            row.append(pool_window.max())\n",
        "        pooled_matrix.append(row)\n",
        "\n",
        "    return pooled_matrix\n",
        "\n",
        "# Example usage\n",
        "matrix = [\n",
        "    [1, 3, 2, 1],\n",
        "    [4, 6, 5, 2],\n",
        "    [7, 8, 9, 4],\n",
        "    [3, 2, 1, 5]\n",
        "]\n",
        "\n",
        "pool_size = 2\n",
        "stride = 2\n",
        "\n",
        "result = max_pooling(matrix, pool_size, stride)\n",
        "for row in result:\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlexKUBNkgcJ"
      },
      "source": [
        "**Question 12**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu7syipn0pHW",
        "outputId": "0448ceb0-44f9-4e5e-ff37-1bfb15df153a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output dimensions: (3, 3)\n"
          ]
        }
      ],
      "source": [
        "def calculate_output_dim(input_dim, filter_size, stride, padding):\n",
        "    \"\"\"\n",
        "    Calculate the output dimensions of a matrix after applying a filter.\n",
        "\n",
        "    Args:\n",
        "        input_dim (tuple of int): Dimensions of the input matrix (rows, cols).\n",
        "        filter_size (int): Size of the filter (assumed square).\n",
        "        stride (int): Stride of the filter.\n",
        "        padding (int): Padding added to the input matrix (assumed symmetric).\n",
        "\n",
        "    Returns:\n",
        "        tuple of int: Output dimensions (rows, cols).\n",
        "    \"\"\"\n",
        "    input_rows, input_cols = input_dim\n",
        "\n",
        "    # Calculate the output dimensions\n",
        "    output_rows = ((input_rows - filter_size + 2 * padding) // stride) + 1\n",
        "    output_cols = ((input_cols - filter_size + 2 * padding) // stride) + 1\n",
        "\n",
        "    return output_rows, output_cols\n",
        "\n",
        "# Example usage\n",
        "input_dim = (5, 5)   # Dimensions of the input matrix\n",
        "filter_size = 3      # Size of the filter\n",
        "stride = 1           # Stride\n",
        "padding = 0          # Padding\n",
        "\n",
        "output_dim = calculate_output_dim(input_dim, filter_size, stride, padding)\n",
        "print(f\"Output dimensions: {output_dim}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWMJEwl52dEQ"
      },
      "source": [
        "**Question 13**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfZ5gvC51Uyi",
        "outputId": "94b8c70b-d527-4496-a93f-676eceb6e267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 51ms/step - accuracy: 0.8817 - loss: 0.3971 - val_accuracy: 0.9832 - val_loss: 0.0524\n",
            "Epoch 2/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 51ms/step - accuracy: 0.9838 - loss: 0.0534 - val_accuracy: 0.9883 - val_loss: 0.0425\n",
            "Epoch 3/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 50ms/step - accuracy: 0.9888 - loss: 0.0376 - val_accuracy: 0.9900 - val_loss: 0.0419\n",
            "Epoch 4/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 49ms/step - accuracy: 0.9926 - loss: 0.0249 - val_accuracy: 0.9878 - val_loss: 0.0425\n",
            "Epoch 5/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 52ms/step - accuracy: 0.9936 - loss: 0.0193 - val_accuracy: 0.9912 - val_loss: 0.0355\n",
            "Test Accuracy: 0.99\n"
          ]
        }
      ],
      "source": [
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0  # Normalize and add channel dimension\n",
        "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0    # Normalize and add channel dimension\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode the labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode the labels\n",
        "\n",
        "# Define the CNN model\n",
        "\"\"\"\n",
        "model summary\n",
        "\n",
        "Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
        "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
        "│ conv2d (Conv2D)                      │ (None, 26, 26, 32)          │             320 │\n",
        "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
        "│ max_pooling2d (MaxPooling2D)         │ (None, 13, 13, 32)          │               0 │\n",
        "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
        "│ conv2d_1 (Conv2D)                    │ (None, 11, 11, 64)          │          18,496 │\n",
        "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
        "│ max_pooling2d_1 (MaxPooling2D)       │ (None, 5, 5, 64)            │               0 │\n",
        "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
        "│ flatten (Flatten)                    │ (None, 1600)                │               0 │\n",
        "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
        "│ dense (Dense)                        │ (None, 128)                 │         204,928 │\n",
        "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
        "│ dense_1 (Dense)                      │ (None, 10)                  │           1,290 │\n",
        "\"\"\"\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOZfanDDaTpz"
      },
      "source": [
        "**Question 14**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tRJ5XZ9hgpU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb5cb79-9d12-4f40-d293-c5b7abffb536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 32ms/step - accuracy: 0.6422 - loss: 0.6058 - val_accuracy: 0.8128 - val_loss: 0.4246\n",
            "Epoch 2/5\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - accuracy: 0.8745 - loss: 0.3121 - val_accuracy: 0.8372 - val_loss: 0.3767\n",
            "Epoch 3/5\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - accuracy: 0.9255 - loss: 0.2005 - val_accuracy: 0.8376 - val_loss: 0.4449\n",
            "Epoch 4/5\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - accuracy: 0.9682 - loss: 0.0995 - val_accuracy: 0.8364 - val_loss: 0.4739\n",
            "Epoch 5/5\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - accuracy: 0.9881 - loss: 0.0445 - val_accuracy: 0.8148 - val_loss: 0.5451\n",
            "Test Accuracy: 0.81\n"
          ]
        }
      ],
      "source": [
        "# Load the IMDB dataset\n",
        "max_features = 10000  # Number of words to consider as features\n",
        "max_len = 100         # Cut texts after this number of words\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)\n",
        "\n",
        "# Define the RNN model\n",
        "\"\"\"\n",
        "model summary\n",
        "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
        "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
        "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
        "│ embedding (Embedding)                │ ?                           │     0 (unbuilt) │\n",
        "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
        "│ simple_rnn (SimpleRNN)               │ ?                           │     0 (unbuilt) │\n",
        "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
        "│ dense_2 (Dense)                      │ ?                           │     0 (unbuilt) │\n",
        "\"\"\"\n",
        "model = Sequential([Embedding(input_dim=max_features, output_dim=32, input_length=max_len),\n",
        "    SimpleRNN(32),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsNzlVYS0wry"
      },
      "source": [
        "**Question 15**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "k_iyNzmF1vp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f427933-49e8-4717-bd74-e2530bfc611d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 51ms/step - accuracy: 0.6886 - loss: 0.5548 - val_accuracy: 0.8464 - val_loss: 0.3611\n",
            "Epoch 2/5\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - accuracy: 0.8940 - loss: 0.2664 - val_accuracy: 0.8408 - val_loss: 0.3561\n",
            "Epoch 3/5\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 49ms/step - accuracy: 0.9283 - loss: 0.1942 - val_accuracy: 0.8300 - val_loss: 0.4318\n",
            "Epoch 4/5\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 53ms/step - accuracy: 0.9464 - loss: 0.1539 - val_accuracy: 0.8252 - val_loss: 0.4547\n",
            "Epoch 5/5\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 49ms/step - accuracy: 0.9524 - loss: 0.1331 - val_accuracy: 0.8280 - val_loss: 0.4477\n",
            "Test Accuracy: 0.83\n"
          ]
        }
      ],
      "source": [
        "# Load the IMDB dataset\n",
        "max_features = 10000  # Number of words to consider as features\n",
        "max_len = 100         # Cut texts after this number of words\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)\n",
        "\n",
        "# Define the LSTM model\n",
        "\"\"\"\n",
        "model summary\n",
        "\n",
        "Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
        "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
        "│ embedding_1 (Embedding)              │ ?                           │     0 (unbuilt) │\n",
        "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
        "│ lstm (LSTM)                          │ ?                           │     0 (unbuilt) │\n",
        "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
        "│ dense_3 (Dense)                      │ ?                           │     0 (unbuilt) │\n",
        "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
        "\"\"\"\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=max_features, output_dim=32, input_length=max_len),  # Word embeddings\n",
        "    LSTM(32, activation='tanh'),  # LSTM layer with 32 units\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}